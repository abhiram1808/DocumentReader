// src/services/llmService.js
const { PDFLoader } = require('@langchain/community/document_loaders/fs/pdf');
const { RecursiveCharacterTextSplitter } = require('langchain/text_splitter');
const { GoogleGenerativeAIEmbeddings } = require('@langchain/google-genai');
const { ChatGoogleGenerativeAI } = require('@langchain/google-genai');
const { RetrievalQAChain } = require('langchain/chains');
const { PromptTemplate } = require('@langchain/core/prompts');
const documentModel = require('../models/documentModel'); // Import document model
const { Document } = require('@langchain/core/documents'); // Import Document class

// Initialize Google Gemini LLM (ensure GOOGLE_API_KEY is in .env)
const model = new ChatGoogleGenerativeAI({
  model: 'gemini-1.5-flash', // <--- CHANGED MODEL HERE
  apiKey: process.env.GOOGLE_API_KEY, // Ensure this is correctly loaded from .env
  temperature: 0.2, // Lower temperature for more focused responses
  maxOutputTokens: 2048, // Increased output tokens for potentially longer summaries/answers
});

// Initialize Google Gemini Embeddings
const embeddings = new GoogleGenerativeAIEmbeddings({
  model: 'embedding-001', // Or another suitable embedding model
  apiKey: process.env.GOOGLE_API_KEY,
});

/**
 * Processes a PDF document: loads, splits, embeds, and stores in vector DB.
 * @param {string} filePath - Path to the PDF file.
 */
const processPdfDocument = async (filePath) => {
  console.log('Loading PDF...');
  const loader = new PDFLoader(filePath);
  const docs = await loader.load();
  console.log(`Loaded ${docs.length} pages.`);

  if (docs.length === 0) {
    throw new Error('No content found in the PDF document.');
  }

  console.log('Splitting documents...');
  const textSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });
  const splitDocs = await textSplitter.splitDocuments(docs);
  console.log(`Split into ${splitDocs.length} chunks.`);

  console.log('Creating/Updating vector store...');
  await documentModel.createAndPersistVectorStore(splitDocs, null, embeddings); // Pass embeddings here
  console.log('Vector store created/updated successfully.');
};

/**
 * Gets an answer to a question from the loaded document knowledge base.
 * @param {string} question - The question to ask.
 * @returns {Promise<string>} The answer generated by the LLM.
 */
const getAnswerFromDocument = async (question) => {
  console.log(`Getting answer for question: "${question}"`);
  const vectorStore = await documentModel.getVectorStore(embeddings); // Still need embeddings for query embedding

  if (!vectorStore) {
    throw new Error('No document knowledge base found. Please upload a document first.');
  }

  // Create a RetrievalQAChain to combine LLM with vector store retriever
  const chain = RetrievalQAChain.fromLLM(model, vectorStore.asRetriever());

  const response = await chain.call({ query: question });
  return response.text;
};

/**
 * Generates a summary of the entire loaded document.
 * @returns {Promise<string>} The summary generated by the LLM.
 */
const getDocumentSummary = async () => {
  console.log('Generating document summary...');
  const allChunks = documentModel.getAllDocumentChunks();

  if (allChunks.length === 0) {
    throw new Error('No document chunks available for summarization. Please upload a document first.');
  }

  // Concatenate all page content for summarization
  const fullDocumentText = allChunks.map(doc => doc.pageContent).join('\n\n');

  const summaryPrompt = PromptTemplate.fromTemplate(
    `Please provide a comprehensive summary of the following document. Focus on main ideas, key arguments, and important conclusions.
    
    Document:
    {document}
    
    Summary:`
  );

  const result = await model.invoke(await summaryPrompt.format({ document: fullDocumentText }));
  return result.content;
};

/**
 * Extracts key concepts from the loaded document.
 * @returns {Promise<string[]>} An array of key concepts.
 */
const getKeyConcepts = async () => {
  console.log('Extracting key concepts...');
  const allChunks = documentModel.getAllDocumentChunks();

  if (allChunks.length === 0) {
    throw new Error('No document chunks available for key concept extraction. Please upload a document first.');
  }

  const fullDocumentText = allChunks.map(doc => doc.pageContent).join('\n\n');

  const conceptsPrompt = PromptTemplate.fromTemplate(
    `From the following document, identify and list the most important key concepts, terms, and topics. Provide them as a comma-separated list.
    
    Document:
    {document}
    
    Key Concepts (comma-separated):`
  );

  const result = await model.invoke(await conceptsPrompt.format({ document: fullDocumentText }));
  return result.content.split(',').map(concept => concept.trim()).filter(concept => concept.length > 0);
};

/**
 * Generates important Q&A pairs from the loaded document.
 * @returns {Promise<Array<{question: string, answer: string}>>} An array of Q&A objects.
 */
const generateImportantQA = async () => {
  console.log('Generating important Q&A pairs...');
  const allChunks = documentModel.getAllDocumentChunks();

  if (allChunks.length === 0) {
    throw new Error('No document chunks available for Q&A generation. Please upload a document first.');
  }

  const fullDocumentText = allChunks.map(doc => doc.pageContent).join('\n\n');

  const qaPrompt = PromptTemplate.fromTemplate(
    `Based on the following document, generate 3-5 important question-answer pairs that would be useful for studying this document. Format each pair as "Q: [Question]\nA: [Answer]".
    
    Document:
    {document}
    
    Q&A Pairs:`
  );

  const result = await model.invoke(await qaPrompt.format({ document: fullDocumentText }));

  const qaPairs = [];
  const lines = result.content.split('\n');
  let currentQuestion = '';
  for (const line of lines) {
    if (line.startsWith('Q:')) {
      currentQuestion = line.substring(2).trim();
    } else if (line.startsWith('A:') && currentQuestion) {
      qaPairs.push({
        question: currentQuestion,
        answer: line.substring(2).trim(),
      });
      currentQuestion = '';
    }
  }
  return qaPairs;
};


module.exports = {
  processPdfDocument,
  getAnswerFromDocument,
  getDocumentSummary,
  getKeyConcepts,
  generateImportantQA,
};
